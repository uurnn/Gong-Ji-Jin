{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pd.set_option('max.columns', 100)\n",
    "\n",
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 21), (15000, 20), (15000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(data_path + 'train.csv')\n",
    "test = pd.read_csv(data_path + 'test.csv')\n",
    "submit = pd.read_csv(data_path + 'submit.csv')\n",
    "\n",
    "train.shape, test.shape, submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WOE、IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WOE(data, feat, label):\n",
    "\n",
    "    bin_values = data[feat].unique()\n",
    "    good_total_num = len(data[data[label]==1])\n",
    "    bad_total_num = len(data[data[label]==0])\n",
    "\n",
    "    woe_dic = {}\n",
    "    df = pd.DataFrame()\n",
    "    for i,val in enumerate(bin_values):\n",
    "        good_num = len(data[(data[feat]==val) & (data[label]==1)])\n",
    "        bad_num = len(data[(data[feat]==val) & (data[label]==0)])\n",
    "        df.loc[i,feat] = val\n",
    "        df.loc[i, feat+'_woe'] = np.log( (good_num/good_total_num) / ((bad_num/bad_total_num+0.0001)) )\n",
    "        woe_dic[val] = np.log( (good_num/good_total_num) / ((bad_num/bad_total_num+0.0001)) )\n",
    "\n",
    "    return woe_dic,df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IV(data, woe_dic, feat, label):\n",
    "    good_total_num = len(data[data[label] == 1])\n",
    "    bad_total_num = len(data[data[label] == 0])\n",
    "    bin_values = data[feat].unique()\n",
    "    feat_IV = 0\n",
    "    for val in bin_values:\n",
    "        woe = woe_dic[val]\n",
    "        good_num = len(data[(data[feat] == val) & (data[label] == 1)])\n",
    "        bad_num = len(data[(data[feat] == val) & (data[label] == 0)])\n",
    "\n",
    "        feat_IV += ((good_num/good_total_num)-(bad_num/bad_total_num))*woe\n",
    "\n",
    "    return feat_IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分箱示例\n",
    "省略等频、等距分箱：pd.qcut、pd.cut，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 决策树分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def optimal_binning_boundary(x: pd.Series, y: pd.Series, nan: float = -999.) -> list:\n",
    "    '''\n",
    "        利用决策树获得最优分箱的边界值列表\n",
    "    '''\n",
    "    boundary = []  # 待return的分箱边界值列表\n",
    "    \n",
    "    x = x.fillna(nan).values  # 填充缺失值\n",
    "    y = y.values\n",
    "    \n",
    "    clf = DecisionTreeClassifier(criterion='entropy',    #“信息熵”最小化准则划分\n",
    "                                 max_leaf_nodes=6,       # 最大叶子节点数\n",
    "                                 min_samples_leaf=0.05)  # 叶子节点样本数量最小占比\n",
    "\n",
    "    clf.fit(x.reshape(-1, 1), y)  # 训练决策树\n",
    "    \n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    threshold = clf.tree_.threshold\n",
    "    \n",
    "    for i in range(n_nodes):\n",
    "        if children_left[i] != children_right[i]:  # 获得决策树节点上的划分边界值\n",
    "            boundary.append(threshold[i])\n",
    "\n",
    "    boundary.sort()\n",
    "\n",
    "    min_x = x.min()\n",
    "    max_x = x.max() + 0.1  # +0.1是为了考虑后续groupby操作时，能包含特征最大值的样本\n",
    "    boundary = [min_x] + boundary + [max_x]\n",
    "\n",
    "    return boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[787.0, 3745.75, 4423.25, 5262.75, 6862.25, 8325.75, 13692.1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_binning_boundary(train['GRJCJS'], train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### best-ks分箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_ks_box(data, var_name, target_col, box_num):\n",
    "    data = data[[var_name, target_col]]\n",
    "    \"\"\"\n",
    "    KS值函数\n",
    "    \"\"\"\n",
    "    def ks_bin(data_, limit):\n",
    "        g = data_.iloc[:, 1].value_counts()[0]\n",
    "        b = data_.iloc[:, 1].value_counts()[1]\n",
    "        data_cro = pd.crosstab(data_.iloc[:, 0], data_.iloc[:, 1])\n",
    "        data_cro[0] = data_cro[0] / g\n",
    "        data_cro[1] = data_cro[1] / b\n",
    "        data_cro_cum = data_cro.cumsum()\n",
    "        ks_list = abs(data_cro_cum[1] - data_cro_cum[0])\n",
    "        ks_list_index = ks_list.nlargest(len(ks_list)).index.tolist()\n",
    "        for i in ks_list_index:\n",
    "            data_1 = data_[data_.iloc[:, 0] <= i]\n",
    "            data_2 = data_[data_.iloc[:, 0] > i]\n",
    "            if len(data_1) >= limit and len(data_2) >= limit:\n",
    "                break\n",
    "        return i\n",
    "\n",
    "    \"\"\"\n",
    "    区间选取函数\n",
    "    \"\"\"\n",
    "\n",
    "    def ks_zone(data_, list_):\n",
    "        list_zone = list()\n",
    "        list_.sort()\n",
    "        n = 0\n",
    "        for val in list_:\n",
    "            m = sum(data_.iloc[:, 0] <= val) - n\n",
    "            n = sum(data_.iloc[:, 0] <= val)\n",
    "#             print(val,' , m:',m,' n:',n)\n",
    "            list_zone.append(m)\n",
    "        #list_zone[i]存放的是list_[i]-list[i-1]之间的数据量的大小\n",
    "        list_zone.append(50000 - sum(list_zone))\n",
    "#         print('sum ',sum(list_zone[:-1]))\n",
    "#         print('list zone ',list_zone)\n",
    "        #选取最大数据量的区间\n",
    "        max_index = list_zone.index(max(list_zone))\n",
    "        if max_index == 0:\n",
    "            rst = [data_.iloc[:, 0].unique().min(), list_[0]]\n",
    "        elif max_index == len(list_):\n",
    "            rst = [list_[-1], data_.iloc[:, 0].unique().max()]\n",
    "        else:\n",
    "            rst = [list_[max_index - 1], list_[max_index]]\n",
    "        return rst\n",
    "\n",
    "    data_ = data.copy()\n",
    "    limit_ = data.shape[0] / 20  # 总体的5%\n",
    "    \"\"\"\"\n",
    "    循环体\n",
    "    \"\"\"\n",
    "    zone = list()\n",
    "    for i in range(box_num - 1):\n",
    "        #找出ks值最大的点作为切点，进行分箱\n",
    "        ks_ = ks_bin(data_, limit_)\n",
    "        zone.append(ks_)\n",
    "        new_zone = ks_zone(data, zone)\n",
    "        data_ = data[(data.iloc[:, 0] > new_zone[0]) & (data.iloc[:, 0] <= new_zone[1])]\n",
    "\n",
    "    zone.append(data.iloc[:, 0].unique().max())\n",
    "    zone.append(data.iloc[:, 0].unique().min())\n",
    "    zone.sort()\n",
    "    return zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[787.0, 3745.5, 4423.0, 5262.5, 6862.0, 13692.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ks_box(train, 'GRJCJS', 'label', box_num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卡方分箱 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算2*2列联表的卡方值\n",
    "def get_chi2_value(arr):\n",
    "    rowsum = arr.sum(axis=1)  # 对行求和\n",
    "    colsum = arr.sum(axis=0)  # 对列求和\n",
    "    n = arr.sum()\n",
    "    emat = np.array([i * j / n for i in rowsum for j in colsum])\n",
    "    arr_flat = arr.reshape(-1)\n",
    "    arr_flat = arr_flat[emat != 0]  # 剔除了期望为0的值,不参与求和计算，不然没法做除法！\n",
    "    emat = emat[emat != 0]  # 剔除了期望为0的值,不参与求和计算，不然没法做除法！\n",
    "    E = (arr_flat - emat) ** 2 / emat\n",
    "    return E.sum()\n",
    "\n",
    "# 自由度以及分位点对应的卡方临界值\n",
    "def get_chi2_threshold(percents, nfree):\n",
    "    return chi2.isf(percents, df=nfree)\n",
    "\n",
    "# 计算卡方切分的切分点\n",
    "def get_chimerge_cutoff(ser, tag, max_groups=None, threshold=None):\n",
    "    freq_tab = pd.crosstab(ser, tag)\n",
    "    cutoffs = freq_tab.index.values  # 保存每个分箱的下标\n",
    "    freq = freq_tab.values  # [M,N_class]大小的矩阵，M是初始箱体的个数，N_class是目标变量类别的个数\n",
    "    while True:\n",
    "        min_value = None #存放所有对相邻区间中卡方值最小的区间的卡方值\n",
    "        min_idx = None #存放最小卡方值的一对区间中第一个区间的下标\n",
    "        for i in range(len(freq) - 1):\n",
    "            chi_value = get_chi2_value(freq[i:(i + 2)]) #计算第i个区间和第i+1个区间的卡方值\n",
    "            if min_value == None or min_value > chi_value:\n",
    "                min_value = chi_value\n",
    "                min_idx = i\n",
    "        if (max_groups is not None and max_groups < len(freq)) or (\n",
    "                threshold is not None and min_value < get_chi2_threshold(threshold, len(cutoffs)-1)):\n",
    "            tmp = freq[min_idx] + freq[min_idx + 1] #合并卡方值最小的那一对区间\n",
    "            freq[min_idx] = tmp\n",
    "            freq = np.delete(freq, min_idx + 1, 0) #删除被合并的区间\n",
    "            cutoffs = np.delete(cutoffs, min_idx + 1, 0)\n",
    "        else:\n",
    "            break\n",
    "    return cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  787. ,   837. ,   847. , ..., 12811. , 12811.5, 13692. ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chimerge_cutoff(train['GRJCJS'], train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卡方分箱 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个卡方分箱（可设置参数置信度水平与箱的个数）停止条件为大于置信水平且小于bin的数目\n",
    "def ChiMerge(df, variable, flag, confidenceVal=3.841, bin=10, sample = None): \n",
    "    '''\n",
    "    运行前需要 import pandas as pd 和 import numpy as np\n",
    "    df:传入一个数据框仅包含一个需要卡方分箱的变量与正负样本标识（正样本为1，负样本为0）\n",
    "    variable:需要卡方分箱的变量名称（字符串）\n",
    "    flag：正负样本标识的名称（字符串）\n",
    "    confidenceVal：置信度水平（默认是不进行抽样95%）\n",
    "    bin：最多箱的数目\n",
    "    sample: 为抽样的数目（默认是不进行抽样），因为如果观测值过多运行会较慢\n",
    "    '''\n",
    "    # 进行是否抽样操作\n",
    "    if sample != None:\n",
    "        df = df.sample(n=sample)\n",
    "    else:\n",
    "        df  \n",
    "         \n",
    "    # 进行数据格式化录入\n",
    "    total_num = df.groupby([variable])[flag].count()  # 统计需分箱变量每个值数目\n",
    "    total_num = pd.DataFrame({'total_num': total_num})  # 创建一个数据框保存之前的结果\n",
    "    positive_class = df.groupby([variable])[flag].sum()  # 统计需分箱变量每个值正样本数\n",
    "    positive_class = pd.DataFrame({'positive_class': positive_class})  # 创建一个数据框保存之前的结果\n",
    "    regroup = pd.merge(total_num, positive_class, left_index=True, right_index=True,\n",
    "                       how='inner')  # 组合total_num与positive_class\n",
    "    regroup.reset_index(inplace=True)\n",
    "    regroup['negative_class'] = regroup['total_num'] - regroup['positive_class']  # 统计需分箱变量每个值负样本数\n",
    "    regroup = regroup.drop('total_num', axis=1)\n",
    "    np_regroup = np.array(regroup)  # 把数据框转化为numpy（提高运行效率）\n",
    "    print('已完成数据读入,正在计算数据初处理')\n",
    " \n",
    "    # 处理连续没有正样本或负样本的区间，并进行区间的合并（以免卡方值计算报错）\n",
    "    i = 0\n",
    "    while (i <= np_regroup.shape[0] - 2):\n",
    "        if ((np_regroup[i, 1] == 0 and np_regroup[i + 1, 1] == 0) or ( np_regroup[i, 2] == 0 and np_regroup[i + 1, 2] == 0)):\n",
    "            np_regroup[i, 1] = np_regroup[i, 1] + np_regroup[i + 1, 1]  # 正样本\n",
    "            np_regroup[i, 2] = np_regroup[i, 2] + np_regroup[i + 1, 2]  # 负样本\n",
    "            np_regroup[i, 0] = np_regroup[i + 1, 0]\n",
    "            np_regroup = np.delete(np_regroup, i + 1, 0)\n",
    "            i = i - 1\n",
    "        i = i + 1\n",
    "  \n",
    "    # 对相邻两个区间进行卡方值计算\n",
    "    chi_table = np.array([])  # 创建一个数组保存相邻两个区间的卡方值\n",
    "    for i in np.arange(np_regroup.shape[0] - 1):\n",
    "        chi = (np_regroup[i, 1] * np_regroup[i + 1, 2] - np_regroup[i, 2] * np_regroup[i + 1, 1]) ** 2 \\\n",
    "          * (np_regroup[i, 1] + np_regroup[i, 2] + np_regroup[i + 1, 1] + np_regroup[i + 1, 2]) / \\\n",
    "          ((np_regroup[i, 1] + np_regroup[i, 2]) * (np_regroup[i + 1, 1] + np_regroup[i + 1, 2]) * (\n",
    "          np_regroup[i, 1] + np_regroup[i + 1, 1]) * (np_regroup[i, 2] + np_regroup[i + 1, 2]))\n",
    "        chi_table = np.append(chi_table, chi)\n",
    "    print('已完成数据初处理，正在进行卡方分箱核心操作')\n",
    " \n",
    "    # 把卡方值最小的两个区间进行合并（卡方分箱核心）\n",
    "    while (1):\n",
    "        if (len(chi_table) <= (bin - 1) and min(chi_table) >= confidenceVal):\n",
    "            break\n",
    "        chi_min_index = np.argwhere(chi_table == min(chi_table))[0]  # 找出卡方值最小的位置索引\n",
    "        np_regroup[chi_min_index, 1] = np_regroup[chi_min_index, 1] + np_regroup[chi_min_index + 1, 1]\n",
    "        np_regroup[chi_min_index, 2] = np_regroup[chi_min_index, 2] + np_regroup[chi_min_index + 1, 2]\n",
    "        np_regroup[chi_min_index, 0] = np_regroup[chi_min_index + 1, 0]\n",
    "        np_regroup = np.delete(np_regroup, chi_min_index + 1, 0)\n",
    " \n",
    "        if (chi_min_index == np_regroup.shape[0] - 1):  # 最小值试最后两个区间的时候\n",
    "            # 计算合并后当前区间与前一个区间的卡方值并替换\n",
    "            chi_table[chi_min_index - 1] = (np_regroup[chi_min_index - 1, 1] * np_regroup[chi_min_index, 2] - np_regroup[chi_min_index - 1, 2] * np_regroup[chi_min_index, 1]) ** 2 \\\n",
    "                                           * (np_regroup[chi_min_index - 1, 1] + np_regroup[chi_min_index - 1, 2] + np_regroup[chi_min_index, 1] + np_regroup[chi_min_index, 2]) / \\\n",
    "                                       ((np_regroup[chi_min_index - 1, 1] + np_regroup[chi_min_index - 1, 2]) * (np_regroup[chi_min_index, 1] + np_regroup[chi_min_index, 2]) * (np_regroup[chi_min_index - 1, 1] + np_regroup[chi_min_index, 1]) * (np_regroup[chi_min_index - 1, 2] + np_regroup[chi_min_index, 2]))\n",
    "            # 删除替换前的卡方值\n",
    "            chi_table = np.delete(chi_table, chi_min_index, axis=0)\n",
    " \n",
    "        else:\n",
    "            # 计算合并后当前区间与前一个区间的卡方值并替换\n",
    "            chi_table[chi_min_index - 1] = (np_regroup[chi_min_index - 1, 1] * np_regroup[chi_min_index, 2] - np_regroup[chi_min_index - 1, 2] * np_regroup[chi_min_index, 1]) ** 2 \\\n",
    "                                       * (np_regroup[chi_min_index - 1, 1] + np_regroup[chi_min_index - 1, 2] + np_regroup[chi_min_index, 1] + np_regroup[chi_min_index, 2]) / \\\n",
    "                                       ((np_regroup[chi_min_index - 1, 1] + np_regroup[chi_min_index - 1, 2]) * (np_regroup[chi_min_index, 1] + np_regroup[chi_min_index, 2]) * (np_regroup[chi_min_index - 1, 1] + np_regroup[chi_min_index, 1]) * (np_regroup[chi_min_index - 1, 2] + np_regroup[chi_min_index, 2]))\n",
    "            # 计算合并后当前区间与后一个区间的卡方值并替换\n",
    "            chi_table[chi_min_index] = (np_regroup[chi_min_index, 1] * np_regroup[chi_min_index + 1, 2] - np_regroup[chi_min_index, 2] * np_regroup[chi_min_index + 1, 1]) ** 2 \\\n",
    "                                       * (np_regroup[chi_min_index, 1] + np_regroup[chi_min_index, 2] + np_regroup[chi_min_index + 1, 1] + np_regroup[chi_min_index + 1, 2]) / \\\n",
    "                                   ((np_regroup[chi_min_index, 1] + np_regroup[chi_min_index, 2]) * (np_regroup[chi_min_index + 1, 1] + np_regroup[chi_min_index + 1, 2]) * (np_regroup[chi_min_index, 1] + np_regroup[chi_min_index + 1, 1]) * (np_regroup[chi_min_index, 2] + np_regroup[chi_min_index + 1, 2]))\n",
    "            # 删除替换前的卡方值\n",
    "            chi_table = np.delete(chi_table, chi_min_index + 1, axis=0)\n",
    "    print('已完成卡方分箱核心操作，正在保存结果')\n",
    " \n",
    "    # 把结果保存成一个数据框\n",
    "    result_data = pd.DataFrame()  # 创建一个保存结果的数据框\n",
    "    result_data['variable'] = [variable] * np_regroup.shape[0]  # 结果表第一列：变量名\n",
    "    list_temp = []\n",
    "    for i in np.arange(np_regroup.shape[0]):\n",
    "        if i == 0:\n",
    "            x = '0' + ',' + str(np_regroup[i, 0])\n",
    "        elif i == np_regroup.shape[0] - 1:\n",
    "            x = str(np_regroup[i - 1, 0]) + '+'\n",
    "        else:\n",
    "            x = str(np_regroup[i - 1, 0]) + ',' + str(np_regroup[i, 0])\n",
    "        list_temp.append(x)\n",
    "    result_data['interval'] = list_temp       # 结果表第二列：区间\n",
    "    result_data['flag_0'] = np_regroup[:, 2]  # 结果表第三列：负样本数目\n",
    "    result_data['flag_1'] = np_regroup[:, 1]  # 结果表第四列：正样本数目\n",
    " \n",
    "    return result_data\n",
    "\n",
    "# #调用函数参数示例\n",
    "# bins = ChiMerge(train, 'GRJCJS','label', confidenceVal=3.841, bin=10,sample=None)\n",
    "# bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
